{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fe736b0-3d97-4a49-ab91-ca4d4811c27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 05:54:35.076017: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-05 05:54:35.112818: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-05 05:54:35.112855: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-05 05:54:35.113822: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-05 05:54:35.120005: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-05 05:54:35.937961: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import base\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50dbe3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "base.fix_seed(SEED)\n",
    "\n",
    "desired_directory = '/home/jovyan/work/spectrum/'\n",
    "os.chdir(desired_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cff661cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = pd.read_csv('Data/05_rikenlipidomics/pos/df_rikenripidomics_pos.csv')\n",
    "\n",
    "df_pos['dataset'] = df_pos['dataset'].str.replace('data/', '', regex=False)\n",
    "df_pos['div2'] = df_pos['AverageMz'].round().astype(int) % 2\n",
    "df_pos['modnum'] = base.cal_mod(df_pos['AverageMz'])\n",
    "\n",
    "df_pos_data2x = pd.read_csv('Data/02_basedata/pos/pos2.csv')\n",
    "df_pos2 = df_pos[df_pos['Ontology'].isin(df_pos_data2x.Ontology.unique().tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a90a55f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from keras.models import load_model\n",
    "loaded_posmodel = load_model(\"Data/03_model/pos/pos_class_model_3\")\n",
    "    \n",
    "with open('Data/03_model/pos/posmodelcolumn_all.pkl', 'rb') as file:\n",
    "    loaded_poscolumns = pickle.load(file)\n",
    "        \n",
    "with open('Data/03_model/pos/pos_replacement_dict_all.pkl', 'rb') as file:\n",
    "    replacement_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae7dfb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive ion mode: test Accuracy\n",
      "----\n",
      "112/112 [==============================] - 1s 7ms/step\n",
      "Different curator - 1st pred : 3381\n",
      "Different curator - candidate : 3521\n",
      "total: 3578\n",
      "----\n",
      "77/77 [==============================] - 0s 6ms/step\n",
      "Sciex 5600 - 1st pred : 2324\n",
      "Sciex 5600 - candidate : 2402\n",
      "total: 2454\n",
      "----\n",
      "25/25 [==============================] - 0s 6ms/step\n",
      "Different company total - 1st pred : 734\n",
      "Different company total - candidate : 774\n",
      "total: 788\n",
      "----\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "Waters - 1st pred : 74\n",
      "Waters - candidate : 74\n",
      "total: 75\n",
      "----\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "Thermo - 1st pred : 158\n",
      "Thermo - candidate : 163\n",
      "total: 163\n",
      "----\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "Agilent - 1st pred : 213\n",
      "Agilent - candidate : 225\n",
      "total: 227\n",
      "----\n",
      "11/11 [==============================] - 0s 5ms/step\n",
      "Bruker - 1st pred : 289\n",
      "Bruker - candidate : 312\n",
      "total: 323\n",
      "----\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "Sciex 6600-SWATH - 1st pred : 194\n",
      "Sciex 6600-SWATH - candidate : 216\n",
      "total: 228\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "#id1から11までのデータ（キュレーター違い）\n",
    "dataset_fromid1to11 = df_pos2[df_pos2['id'].between(1, 11)][['dataset','id']].drop_duplicates()['dataset'].tolist()\n",
    "df_pos_data_sel1 = df_pos2[df_pos2['dataset'].isin(dataset_fromid1to11)]\n",
    "print('Positive ion mode: test Accuracy')\n",
    "print('----')\n",
    "pred1st1, predcandidate1, num1 = base.cal_accscore(df_pos_data_sel1, replacement_dict, loaded_poscolumns, loaded_posmodel)\n",
    "print('Different curator - 1st pred :', pred1st1)\n",
    "print('Different curator - candidate :', predcandidate1)\n",
    "print('total:', num1)\n",
    "print('----')\n",
    "\n",
    "#id18から28までのデータ（装置のバージョン違い）\n",
    "dataset_fromid18to28 = df_pos2[df_pos2['id'].between(18, 28)][['dataset','id']].drop_duplicates()['dataset'].tolist()\n",
    "df_pos_data_sel2 = df_pos2[df_pos2['dataset'].isin(dataset_fromid18to28)]\n",
    "pred1st2, predcandidate2, num2 = base.cal_accscore(df_pos_data_sel2, replacement_dict, loaded_poscolumns, loaded_posmodel)\n",
    "print('Sciex 5600 - 1st pred :', pred1st2)\n",
    "print('Sciex 5600 - candidate :', predcandidate2)\n",
    "print('total:', num2)\n",
    "print('----')\n",
    "\n",
    "#id78-80,83,84のデータ（装置の会社違い）\n",
    "dataset_fromidaround80 = df_pos2[df_pos2['id'].isin([78,79,80,83,84])][['dataset','id']].drop_duplicates()['dataset'].tolist()\n",
    "df_pos_data_sel3 = df_pos2[df_pos2['dataset'].isin(dataset_fromidaround80)]\n",
    "pred1st3, predcandidate3, num3 = base.cal_accscore(df_pos_data_sel3, replacement_dict, loaded_poscolumns, loaded_posmodel)\n",
    "print('Different company total - 1st pred :', pred1st3)\n",
    "print('Different company total - candidate :', predcandidate3)\n",
    "print('total:', num3)\n",
    "print('----')\n",
    "\n",
    "#Waters\n",
    "dataset_fromWaters = df_pos2[df_pos2['id'].isin([78])][['dataset','id']].drop_duplicates()['dataset'].tolist()\n",
    "df_pos_data_sel4 = df_pos2[df_pos2['dataset'].isin(dataset_fromWaters)]\n",
    "pred1st4, predcandidate4, num4 = base.cal_accscore(df_pos_data_sel4, replacement_dict, loaded_poscolumns, loaded_posmodel)\n",
    "print('Waters - 1st pred :', pred1st4)\n",
    "print('Waters - candidate :', predcandidate4)\n",
    "print('total:', num4)\n",
    "print('----')\n",
    "\n",
    "#Thermo\n",
    "dataset_fromThermo = df_pos2[df_pos2['id'].isin([79])][['dataset','id']].drop_duplicates()['dataset'].tolist()\n",
    "df_pos_data_sel5 = df_pos2[df_pos2['dataset'].isin(dataset_fromThermo)]\n",
    "pred1st5, predcandidate5, num5 = base.cal_accscore(df_pos_data_sel5, replacement_dict, loaded_poscolumns, loaded_posmodel)\n",
    "print('Thermo - 1st pred :', pred1st5)\n",
    "print('Thermo - candidate :', predcandidate5)\n",
    "print('total:', num5)\n",
    "print('----')\n",
    "\n",
    "#Agilent\n",
    "dataset_fromAgilent = df_pos2[df_pos2['id'].isin([80])][['dataset','id']].drop_duplicates()['dataset'].tolist()\n",
    "df_pos_data_sel6 = df_pos2[df_pos2['dataset'].isin(dataset_fromAgilent)]\n",
    "pred1st6, predcandidate6, num6 = base.cal_accscore(df_pos_data_sel6, replacement_dict, loaded_poscolumns, loaded_posmodel)\n",
    "print('Agilent - 1st pred :', pred1st6)\n",
    "print('Agilent - candidate :', predcandidate6)\n",
    "print('total:', num6)\n",
    "print('----')\n",
    "\n",
    "\n",
    "#Bruker\n",
    "dataset_fromBruker = df_pos2[df_pos2['id'].isin([83,84])][['dataset','id']].drop_duplicates()['dataset'].tolist()\n",
    "df_pos_data_sel7 = df_pos2[df_pos2['dataset'].isin(dataset_fromBruker)]\n",
    "pred1st7, predcandidate7, num7 = base.cal_accscore(df_pos_data_sel7, replacement_dict, loaded_poscolumns, loaded_posmodel)\n",
    "print('Bruker - 1st pred :', pred1st7)\n",
    "print('Bruker - candidate :', predcandidate7)\n",
    "print('total:', num7)\n",
    "print('----')\n",
    "\n",
    "\n",
    "#Sciex 6600-SWATH\n",
    "dataset_fromSWATH = df_pos2[df_pos2['id'].isin([81])][['dataset','id']].drop_duplicates()['dataset'].tolist()\n",
    "df_pos_data_sel8 = df_pos2[df_pos2['dataset'].isin(dataset_fromSWATH)]\n",
    "pred1st8, predcandidate8, num8 = base.cal_accscore(df_pos_data_sel8, replacement_dict, loaded_poscolumns, loaded_posmodel)\n",
    "print('Sciex 6600-SWATH - 1st pred :', pred1st8)\n",
    "print('Sciex 6600-SWATH - candidate :', predcandidate8)\n",
    "print('total:', num8)\n",
    "print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48b607e5-daf9-4217-8681-73cd29300dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_result = pd.read_csv('Data/03_model/pos/df_pos_model_pred_result.csv').rename(columns={'Unnamed: 0':'name', '0':'value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab415734-dbde-42b9-a590-3fc77a7343e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [#['Train(Sciex TripleTOF 6600)', df_model_result.value.tolist()[2] , df_model_result.value.tolist()[0], df_model_result.value.tolist()[1]-df_model_result.value.tolist()[0]],\n",
    "        #['Test(Sciex TripleTOF 6600)', df_model_result.value.tolist()[5], df_model_result.value.tolist()[3], df_model_result.value.tolist()[4]-df_model_result.value.tolist()[3]],\n",
    "        ['Different curator(Sciex TripleTOF 6600)', len(df_pos_data_sel1), pred1st1, predcandidate1-pred1st1],\n",
    "        ['Different version(Sciex TripleTOF 5600+)', len(df_pos_data_sel2), pred1st2, predcandidate2-pred1st2],\n",
    "        ['Different marchine(total)', len(df_pos_data_sel3), pred1st3, predcandidate3-pred1st3],\n",
    "        ['Waters XevoG2 QTOF', len(df_pos_data_sel4), pred1st4, predcandidate4-pred1st4],\n",
    "        ['Thermo Q Exactive Plus', len(df_pos_data_sel5), pred1st5, predcandidate5-pred1st5],\n",
    "        ['Agilent 6546 QTOF', len(df_pos_data_sel6), pred1st6, predcandidate6-pred1st6],\n",
    "        ['Bruker timsTOF Pro', len(df_pos_data_sel7), pred1st7, predcandidate7-pred1st7],\n",
    "        ['Sciex TripleTOF 6600(SWATH)', len(df_pos_data_sel8), pred1st8, predcandidate8-pred1st8]]\n",
    "\n",
    "df_predresult = pd.DataFrame(data, columns=['Name', 'Sample number', '1st pred', 'Candidate'])\n",
    "df_predresult['Non predicted'] = df_predresult['Sample number']-(df_predresult['1st pred']+df_predresult['Candidate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc222d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predresult.to_csv('Data/03_model/pos/df_pos_model_pred_result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
